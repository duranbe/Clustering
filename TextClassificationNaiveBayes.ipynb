{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification using  Naive Bayes\n",
    "### Based on IMDB dataset\n",
    "\n",
    "Source Annexe : https://web.stanford.edu/~jurafsky/slp3/slides/7_NB.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list=glob.glob(\"./data/movie-reviews-en/train/pos/*.txt\")\n",
    "neg_list=glob.glob(\"./data/movie-reviews-en/train/neg/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_word = 10000    #Nb of words to keep in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get all text files as a list of string\n",
    "def get_text_list(file_list):\n",
    "    text_list = []\n",
    "    \n",
    "    for file in file_list:\n",
    "        \n",
    "        with open(file,'r') as f:\n",
    "            text_list.append(f.read())\n",
    "            \n",
    "    return(text_list)\n",
    "        \n",
    "pos_text = ' '.join(get_text_list(pos_list))\n",
    "neg_text = ' '.join(get_text_list(neg_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small Preprocessing\n",
    "\n",
    "Remove punctuation and line escape char '\\n'\n",
    "\n",
    "Then we only keep the n_word most occuring word across all text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_text = pos_text.translate(str.maketrans('','', string.punctuation)).replace('\\n','')\n",
    "pos_count = dict(Counter(pos_text.split()).most_common(n_word))\n",
    "\n",
    "neg_text = neg_text.translate(str.maketrans('','', string.punctuation)).replace('\\n','')\n",
    "neg_count = dict(Counter(neg_text.split()).most_common(n_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilty functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return the probabilty to have the input word knowing the class\n",
    "#P(wi|Cj)\n",
    "#P('nice'|Positive)\n",
    "\n",
    "def proba_word(word,counter):    \n",
    "    \n",
    "    try: \n",
    "        # If the word is in our Vocabulary\n",
    "        r = (counter[word]+1)/(sum(counter.values())+len(counter))\n",
    "        \n",
    "    except KeyError:\n",
    "        # Else counter[word] = 0 \n",
    "        r = (1)/(sum(counter.values())+len(counter))\n",
    "        \n",
    "    return(np.float64(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the sum of the log probabilities of each word in the input text\n",
    "\n",
    "def proba_text(text,counter):   \n",
    "    \n",
    "    probs=[]\n",
    "    \n",
    "    for word in text.split():\n",
    "        probs.append(np.log(proba_word(word,counter)))\n",
    "        \n",
    "    return(np.sum(probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NBmodel(text_array):\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for text in text_array:\n",
    "        \n",
    "        text = text.translate(str.maketrans('','', string.punctuation)).replace('\\n','')\n",
    "        probs = [proba_text(text,neg_count),proba_text(text,pos_count)]\n",
    "        predictions.append(np.argmax(probs))\n",
    "        \n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_test_list = glob.glob(\"./data/movie-reviews-en/test/pos/*.txt\")\n",
    "neg_test_list = glob.glob(\"./data/movie-reviews-en/test/neg/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_test_text = get_text_list(pos_test_list)      \n",
    "neg_test_text = get_text_list(neg_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_results = NBmodel(pos_test_text)\n",
    "neg_results = NBmodel(neg_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Negative Accuracy : 0.9 '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\" Negative Accuracy : {(len(neg_results)-np.sum(neg_results))/(len(neg_results))} \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive Accuracy : 0.73'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Positive Accuracy : {np.sum(pos_results)/(len(pos_results))}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
