{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification using  Naive Bayes\n",
    "### Based on IMDB dataset\n",
    "\n",
    "Source Annexe : https://web.stanford.edu/~jurafsky/slp3/slides/7_NB.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob #list .txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list=glob.glob(\"./data/movie-reviews-en/train/pos/*.txt\")\n",
    "neg_list=glob.glob(\"./data/movie-reviews-en/train/neg/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_word = 10000    #Nb of words to keep in the vocabulary\n",
    "\n",
    "pos_text = ''\n",
    "#Creating Positive Vocabulary\n",
    "for file in pos_list:\n",
    "    f = open(file, \"r\")\n",
    "    pos_text += f.read()\n",
    "    f.close()\n",
    "\n",
    "\n",
    "neg_text = ''\n",
    "#Creating Negative Vocabulary\n",
    "for file in neg_list:\n",
    "    f = open(file, \"r\")\n",
    "    neg_text += f.read() \n",
    "    f.close()\n",
    "\n",
    "#Pre Processing and saving as dict to keep only n_word most common\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small Preprocessing\n",
    "\n",
    "Remove punctuation and line escape char '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_text = pos_text.translate(str.maketrans('','', string.punctuation)).replace('\\n','')\n",
    "pos_count = dict(Counter(pos_text.split()).most_common(n_word))\n",
    "\n",
    "neg_text = neg_text.translate(str.maketrans('','', string.punctuation)).replace('\\n','')\n",
    "neg_count = dict(Counter(neg_text.split()).most_common(n_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return the probabilty to have the input word knowing the class\n",
    "#P(wi|Cj)\n",
    "#P('nice'|Positive)\n",
    "\n",
    "def proba_word(word,counter):    \n",
    "    try: \n",
    "        # If the word is in our Vocabulary\n",
    "        r = (counter[word]+1)/(sum(counter.values())+len(counter))\n",
    "    except KeyError:\n",
    "        # Else counter[word] = 0 \n",
    "        r = (1)/(sum(counter.values())+len(counter))\n",
    "    return(np.float64(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the sum of the log probabilities of each word in the input text\n",
    "def proba_text(text,counter):\n",
    "    probs=[]\n",
    "    for word in text.split():\n",
    "        probs.append(np.log(proba_word(word,counter)))\n",
    "    return(np.sum(probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on the positive test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_test_list=glob.glob(\"./data/movie-reviews-en/test/pos/*.txt\")\n",
    "pos_results=[]\n",
    "\n",
    "for file in pos_test_list:\n",
    "    f = open(file,\"r\")\n",
    "    text = f.read()\n",
    "    f.close()\n",
    "    text = text.translate(str.maketrans('','', string.punctuation)).replace('\\n','')\n",
    "    probs = [proba_text(text,neg_count),proba_text(text,pos_count)]\n",
    "    pos_results.append(np.argmax(probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Score : 0.73'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Score : {np.sum(pos_results)/(len(pos_results))}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on the negative test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_test_list=glob.glob(\"./data/movie-reviews-en/test/neg/*.txt\")\n",
    "neg_results=[]\n",
    "\n",
    "for file in neg_test_list:\n",
    "    f = open(file,\"r\")\n",
    "    text = f.read()\n",
    "    f.close()\n",
    "    text = text.translate(str.maketrans('','', string.punctuation)).replace('\\n','')\n",
    "    probs = [proba_text(text,neg_count),proba_text(text,pos_count)]\n",
    "    neg_results.append(np.argmax(probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Score : 0.9 '"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Score : {(len(neg_results)-np.sum(neg_results))/(len(neg_results))} \""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
